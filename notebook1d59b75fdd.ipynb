{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Hindi Audio Transcription and Translation\n# Complete solution for Google Colab\n\n# Step 1: Install required packages\n!pip install torch torchvision torchaudio\n!pip install transformers\n!pip install openai-whisper\n!pip install librosa\n!pip install soundfile\n\nimport whisper\nimport torch\nfrom transformers import MarianMTModel, MarianTokenizer\nimport librosa\nimport soundfile as sf\nimport numpy as np\nimport os\nfrom google.colab import files\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nclass HindiTranscriptionTranslator:\n    def __init__(self):\n        \"\"\"Initialize the transcription and translation models\"\"\"\n        print(\"Loading models... This may take a few minutes on first run.\")\n        \n        # Load Whisper model for speech-to-text\n        print(\"Loading Whisper model...\")\n        self.whisper_model = whisper.load_model(\"base\")  # You can use \"small\", \"medium\", \"large\" for better accuracy\n        \n        # Load MarianMT model for Hindi to English translation\n        print(\"Loading translation model...\")\n        self.translation_model_name = \"Helsinki-NLP/opus-mt-hi-en\"\n        self.tokenizer = MarianTokenizer.from_pretrained(self.translation_model_name)\n        self.translation_model = MarianMTModel.from_pretrained(self.translation_model_name)\n        \n        print(\"Models loaded successfully!\")\n    \n    def preprocess_audio(self, audio_path):\n        \"\"\"Preprocess audio file for Whisper\"\"\"\n        # Load audio file\n        audio, sr = librosa.load(audio_path, sr=16000)  # Whisper expects 16kHz\n        return audio\n    \n    def transcribe_audio(self, audio_path):\n        \"\"\"Transcribe Hindi audio to Hindi text\"\"\"\n        print(f\"Transcribing audio: {audio_path}\")\n        \n        # Transcribe with Whisper\n        result = self.whisper_model.transcribe(audio_path, language=\"hi\")\n        hindi_text = result[\"text\"]\n        \n        print(f\"Hindi Transcription: {hindi_text}\")\n        return hindi_text\n    \n    def translate_text(self, hindi_text):\n        \"\"\"Translate Hindi text to English\"\"\"\n        print(\"Translating to English...\")\n        \n        # Tokenize the Hindi text\n        inputs = self.tokenizer(hindi_text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n        \n        # Generate translation\n        with torch.no_grad():\n            outputs = self.translation_model.generate(**inputs, max_length=512, num_beams=4, early_stopping=True)\n        \n        # Decode the translation\n        english_text = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n        \n        print(f\"English Translation: {english_text}\")\n        return english_text\n    \n    def process_audio_file(self, audio_path):\n        \"\"\"Complete pipeline: audio -> Hindi text -> English translation\"\"\"\n        try:\n            # Step 1: Transcribe audio to Hindi text\n            hindi_text = self.transcribe_audio(audio_path)\n            \n            # Step 2: Translate Hindi text to English\n            english_text = self.translate_text(hindi_text)\n            \n            return {\n                \"hindi_text\": hindi_text,\n                \"english_text\": english_text\n            }\n            \n        except Exception as e:\n            print(f\"Error processing audio: {str(e)}\")\n            return None\n\n# Usage example and testing functions\n\ndef upload_and_process():\n    \"\"\"Upload audio file and process it\"\"\"\n    print(\"Please upload your Hindi audio file (supported formats: wav, mp3, m4a, etc.)\")\n    uploaded = files.upload()\n    \n    if not uploaded:\n        print(\"No file uploaded!\")\n        return\n    \n    # Get the uploaded file path\n    audio_file = list(uploaded.keys())[0]\n    print(f\"Processing file: {audio_file}\")\n    \n    # Initialize the processor\n    processor = HindiTranscriptionTranslator()\n    \n    # Process the audio\n    result = processor.process_audio_file(audio_file)\n    \n    if result:\n        print(\"\\n\" + \"=\"*50)\n        print(\"RESULTS:\")\n        print(\"=\"*50)\n        print(f\"Hindi Text: {result['hindi_text']}\")\n        print(f\"English Translation: {result['english_text']}\")\n        print(\"=\"*50)\n        \n        # Save results to file\n        with open(\"transcription_results.txt\", \"w\", encoding=\"utf-8\") as f:\n            f.write(f\"Hindi Transcription: {result['hindi_text']}\\n\")\n            f.write(f\"English Translation: {result['english_text']}\\n\")\n        \n        print(\"Results saved to 'transcription_results.txt'\")\n        \n        # Download results file\n        files.download(\"transcription_results.txt\")\n    \n    return result\n\ndef test_with_sample_text():\n    \"\"\"Test translation with sample Hindi text\"\"\"\n    print(\"Testing translation with sample Hindi text...\")\n    \n    processor = HindiTranscriptionTranslator()\n    \n    # Sample Hindi texts for testing\n    sample_texts = [\n        \"नमस्ते, मेरा नाम राहुल है।\",\n        \"आज मौसम बहुत अच्छा है।\",\n        \"मैं भारत से हूँ और हिंदी बोलता हूँ।\"\n    ]\n    \n    for hindi_text in sample_texts:\n        print(f\"\\nHindi: {hindi_text}\")\n        english_text = processor.translate_text(hindi_text)\n        print(f\"English: {english_text}\")\n\ndef create_sample_audio():\n    \"\"\"Create a sample audio file for testing (using text-to-speech)\"\"\"\n    try:\n        !pip install gTTS\n        from gtts import gTTS\n        \n        # Sample Hindi text\n        hindi_text = \"नमस्ते, मेरा नाम राहुल है और मैं भारत से हूँ।\"\n        \n        # Create TTS audio\n        tts = gTTS(text=hindi_text, lang='hi')\n        tts.save(\"sample_hindi_audio.mp3\")\n        \n        print(\"Sample audio created: sample_hindi_audio.mp3\")\n        return \"sample_hindi_audio.mp3\"\n        \n    except Exception as e:\n        print(f\"Could not create sample audio: {e}\")\n        return None\n\n# Main execution\nif __name__ == \"__main__\":\n    print(\"Hindi Audio Transcription and Translation System\")\n    print(\"=\" * 50)\n    \n    print(\"\\nChoose an option:\")\n    print(\"1. Upload and process your Hindi audio file\")\n    print(\"2. Test translation with sample Hindi text\")\n    print(\"3. Create and process sample audio\")\n    \n    choice = input(\"\\nEnter your choice (1/2/3): \")\n    \n    if choice == \"1\":\n        upload_and_process()\n    elif choice == \"2\":\n        test_with_sample_text()\n    elif choice == \"3\":\n        sample_file = create_sample_audio()\n        if sample_file:\n            processor = HindiTranscriptionTranslator()\n            result = processor.process_audio_file(sample_file)\n    else:\n        print(\"Invalid choice. Running upload and process by default...\")\n        upload_and_process()\n\n# Alternative: Direct function calls for custom usage\n\"\"\"\n# For direct usage in your code:\n\n# Initialize the processor\nprocessor = HindiTranscriptionTranslator()\n\n# Process an audio file\nresult = processor.process_audio_file(\"your_audio_file.wav\")\n\n# Or just translate text\nenglish_text = processor.translate_text(\"आपका हिंदी टेक्स्ट यहाँ\")\n\"\"\"\n\nprint(\"\\n\" + \"=\"*50)\nprint(\"Setup complete! Run the cells above to start processing.\")\nprint(\"=\"*50)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-01T16:29:29.448902Z","iopub.execute_input":"2025-08-01T16:29:29.449207Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\nRequirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\nRequirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.5.1)\nCollecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (1.26.4)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.2.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchvision) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchvision) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->torchvision) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->torchvision) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->torchvision) (2024.2.0)\nDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m72.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m57.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m29.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.6.82\n    Uninstalling nvidia-curand-cu12-10.3.6.82:\n      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n  Attempting uninstall: nvidia-cuda-runtime-cu12\n    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-cupti-cu12\n    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\nSuccessfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\nRequirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.52.4)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.33.1)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.4)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.2)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.5.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.14.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.5)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.6.15)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\nCollecting openai-whisper\n  Downloading openai_whisper-20250625.tar.gz (803 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m803.2/803.2 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: more-itertools in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (10.7.0)\nRequirement already satisfied: numba in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (0.60.0)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (1.26.4)\nRequirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (0.9.0)\nRequirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (2.6.0+cu124)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (4.67.1)\nRequirement already satisfied: triton>=2 in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (3.2.0)\nRequirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba->openai-whisper) (0.43.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->openai-whisper) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->openai-whisper) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->openai-whisper) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->openai-whisper) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->openai-whisper) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->openai-whisper) (2.4.1)\nRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken->openai-whisper) (2024.11.6)\nRequirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken->openai-whisper) (2.32.4)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (4.14.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (2025.5.1)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (12.3.1.170)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (12.4.127)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->openai-whisper) (1.3.0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2025.6.15)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->openai-whisper) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->openai-whisper) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->openai-whisper) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->openai-whisper) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->openai-whisper) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->openai-whisper) (2024.2.0)\nBuilding wheels for collected packages: openai-whisper\n  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for openai-whisper: filename=openai_whisper-20250625-py3-none-any.whl size=803979 sha256=4599b0c36c73f5ae96253b97fa8a84a75398d61d50e00f5605157c082bd52c84\n  Stored in directory: /root/.cache/pip/wheels/32/d2/9a/801b5cc5b2a1af2e280089b71c326711a682fc1d50ea29d0ed\nSuccessfully built openai-whisper\nInstalling collected packages: openai-whisper\nSuccessfully installed openai-whisper-20250625\nRequirement already satisfied: librosa in /usr/local/lib/python3.11/dist-packages (0.11.0)\nRequirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.11/dist-packages (from librosa) (3.0.1)\nRequirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.60.0)\nRequirement already satisfied: numpy>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.26.4)\nRequirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.15.3)\nRequirement already satisfied: scikit-learn>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.2.2)\nRequirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.5.1)\nRequirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (4.4.2)\nRequirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.13.1)\nRequirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.8.2)\nRequirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.5.0.post1)\nRequirement already satisfied: typing_extensions>=4.1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (4.14.0)\nRequirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.4)\nRequirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.1.1)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from lazy_loader>=0.1->librosa) (25.0)\nRequirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.0->librosa) (0.43.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.22.3->librosa) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.22.3->librosa) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.22.3->librosa) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.22.3->librosa) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.22.3->librosa) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.22.3->librosa) (2.4.1)\nRequirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa) (4.3.8)\nRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa) (2.32.4)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.1.0->librosa) (3.6.0)\nRequirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile>=0.12.1->librosa) (1.17.1)\nRequirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.22)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2025.6.15)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.22.3->librosa) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.22.3->librosa) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.22.3->librosa) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.22.3->librosa) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.22.3->librosa) (2024.2.0)\nRequirement already satisfied: soundfile in /usr/local/lib/python3.11/dist-packages (0.13.1)\nRequirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile) (1.17.1)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from soundfile) (1.26.4)\nRequirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile) (2.22)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->soundfile) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->soundfile) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->soundfile) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->soundfile) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->soundfile) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->soundfile) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->soundfile) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->soundfile) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->soundfile) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->soundfile) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->soundfile) (2024.2.0)\n","output_type":"stream"},{"name":"stderr","text":"2025-08-01 16:32:16.760030: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1754065937.122558      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1754065937.222158      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"Hindi Audio Transcription and Translation System\n==================================================\n\nChoose an option:\n1. Upload and process your Hindi audio file\n2. Test translation with sample Hindi text\n3. Create and process sample audio\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"\nEnter your choice (1/2/3):  1\n"},{"name":"stdout","text":"Please upload your Hindi audio file (supported formats: wav, mp3, m4a, etc.)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n     <input type=\"file\" id=\"files-e8c043a0-d38c-4fc3-87e6-c67197084ac7\" name=\"files[]\" multiple disabled\n        style=\"border:none\" />\n     <output id=\"result-e8c043a0-d38c-4fc3-87e6-c67197084ac7\">\n      Upload widget is only available when the cell has been executed in the\n      current browser session. Please rerun this cell to enable.\n      </output>\n      <script>// Copyright 2017 Google LLC\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//      http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\n/**\n * @fileoverview Helpers for google.colab Python module.\n */\n(function(scope) {\nfunction span(text, styleAttributes = {}) {\n  const element = document.createElement('span');\n  element.textContent = text;\n  for (const key of Object.keys(styleAttributes)) {\n    element.style[key] = styleAttributes[key];\n  }\n  return element;\n}\n\n// Max number of bytes which will be uploaded at a time.\nconst MAX_PAYLOAD_SIZE = 100 * 1024;\n\nfunction _uploadFiles(inputId, outputId) {\n  const steps = uploadFilesStep(inputId, outputId);\n  const outputElement = document.getElementById(outputId);\n  // Cache steps on the outputElement to make it available for the next call\n  // to uploadFilesContinue from Python.\n  outputElement.steps = steps;\n\n  return _uploadFilesContinue(outputId);\n}\n\n// This is roughly an async generator (not supported in the browser yet),\n// where there are multiple asynchronous steps and the Python side is going\n// to poll for completion of each step.\n// This uses a Promise to block the python side on completion of each step,\n// then passes the result of the previous step as the input to the next step.\nfunction _uploadFilesContinue(outputId) {\n  const outputElement = document.getElementById(outputId);\n  const steps = outputElement.steps;\n\n  const next = steps.next(outputElement.lastPromiseValue);\n  return Promise.resolve(next.value.promise).then((value) => {\n    // Cache the last promise value to make it available to the next\n    // step of the generator.\n    outputElement.lastPromiseValue = value;\n    return next.value.response;\n  });\n}\n\n/**\n * Generator function which is called between each async step of the upload\n * process.\n * @param {string} inputId Element ID of the input file picker element.\n * @param {string} outputId Element ID of the output display.\n * @return {!Iterable<!Object>} Iterable of next steps.\n */\nfunction* uploadFilesStep(inputId, outputId) {\n  const inputElement = document.getElementById(inputId);\n  inputElement.disabled = false;\n\n  const outputElement = document.getElementById(outputId);\n  outputElement.innerHTML = '';\n\n  const pickedPromise = new Promise((resolve) => {\n    inputElement.addEventListener('change', (e) => {\n      resolve(e.target.files);\n    });\n  });\n\n  const cancel = document.createElement('button');\n  inputElement.parentElement.appendChild(cancel);\n  cancel.textContent = 'Cancel upload';\n  const cancelPromise = new Promise((resolve) => {\n    cancel.onclick = () => {\n      resolve(null);\n    };\n  });\n\n  // Wait for the user to pick the files.\n  const files = yield {\n    promise: Promise.race([pickedPromise, cancelPromise]),\n    response: {\n      action: 'starting',\n    }\n  };\n\n  cancel.remove();\n\n  // Disable the input element since further picks are not allowed.\n  inputElement.disabled = true;\n\n  if (!files) {\n    return {\n      response: {\n        action: 'complete',\n      }\n    };\n  }\n\n  for (const file of files) {\n    const li = document.createElement('li');\n    li.append(span(file.name, {fontWeight: 'bold'}));\n    li.append(span(\n        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n        `last modified: ${\n            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n                                    'n/a'} - `));\n    const percent = span('0% done');\n    li.appendChild(percent);\n\n    outputElement.appendChild(li);\n\n    const fileDataPromise = new Promise((resolve) => {\n      const reader = new FileReader();\n      reader.onload = (e) => {\n        resolve(e.target.result);\n      };\n      reader.readAsArrayBuffer(file);\n    });\n    // Wait for the data to be ready.\n    let fileData = yield {\n      promise: fileDataPromise,\n      response: {\n        action: 'continue',\n      }\n    };\n\n    // Use a chunked sending to avoid message size limits. See b/62115660.\n    let position = 0;\n    do {\n      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n      const chunk = new Uint8Array(fileData, position, length);\n      position += length;\n\n      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n      yield {\n        response: {\n          action: 'append',\n          file: file.name,\n          data: base64,\n        },\n      };\n\n      let percentDone = fileData.byteLength === 0 ?\n          100 :\n          Math.round((position / fileData.byteLength) * 100);\n      percent.textContent = `${percentDone}% done`;\n\n    } while (position < fileData.byteLength);\n  }\n\n  // All done.\n  yield {\n    response: {\n      action: 'complete',\n    }\n  };\n}\n\nscope.google = scope.google || {};\nscope.google.colab = scope.google.colab || {};\nscope.google.colab._files = {\n  _uploadFiles,\n  _uploadFilesContinue,\n};\n})(self);\n</script> "},"metadata":{}}],"execution_count":null},{"cell_type":"code","source":"if __name__ == \"__main__\":\n    print(\"Hindi Audio Transcription and Translation System\")\n    print(\"=\" * 50)\n    \n    print(\"\\nChoose an option:\")\n    print(\"1. Upload and process your Hindi audio file\")\n    print(\"2. Test translation with sample Hindi text\")\n    print(\"3. Create and process sample audio\")\n    \n    choice = input(\"\\nEnter your choice (1/2/3): \")\n    \n    if choice == \"1\":\n        upload_and_process()\n    elif choice == \"2\":\n        test_with_sample_text()\n    elif choice == \"3\":\n        sample_file = create_sample_audio()\n        if sample_file:\n            processor = HindiTranscriptionTranslator()\n            result = processor.process_audio_file(sample_file)\n    else:\n        print(\"Invalid choice. Running upload and process by default...\")\n        upload_and_process()\n\n# Alternative: Direct function calls for custom usage\n\"\"\"\n# For direct usage in your code:\n\n# Initialize the processor\nprocessor = HindiTranscriptionTranslator()\n\n# Process an audio file\nresult = processor.process_audio_file(\"your_audio_file.wav\")\n\n# Or just translate text\nenglish_text = processor.translate_text(\"आपका हिंदी टेक्स्ट यहाँ\")\n\"\"\"\n\nprint(\"\\n\" + \"=\"*50)\nprint(\"Setup complete! Run the cells above to start processing.\")\nprint(\"=\"*50)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}