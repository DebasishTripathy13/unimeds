{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade --quiet speechrecognition\n",
        "!pip install --upgrade --quiet accelerate\n",
        "!pip install --upgrade --quiet bitsandbytes\n",
        "!pip install --upgrade --quiet transformers"
      ],
      "metadata": {
        "id": "4S2zK2p80TaY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt update\n",
        "!sudo apt install portaudio19-dev python3-pyaudio\n"
      ],
      "metadata": {
        "id": "5PMWgLXc1s-h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R6YXhfC80G5R"
      },
      "outputs": [],
      "source": [
        "# Copyright 2025 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "\n",
        "\"\"\"\n",
        "Speech-to-Text Medical Assistant using Google MedGemma\n",
        "This application integrates speech recognition with MedGemma for medical Q&A.\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import speech_recognition as sr\n",
        "import pyaudio\n",
        "import torch\n",
        "from transformers import BitsAndBytesConfig, pipeline, AutoModelForCausalLM, AutoTokenizer\n",
        "from IPython.display import Markdown, display\n",
        "from PIL import Image\n",
        "import warnings\n",
        "\n",
        "# Suppress warnings for cleaner output\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "class SpeechToTextMedGemma:\n",
        "    \"\"\"\n",
        "    A comprehensive speech-to-text medical assistant using Google MedGemma.\n",
        "    Supports both text-only and multimodal (image + text) interactions.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, model_variant=\"4b-it\", use_quantization=True, is_thinking=False):\n",
        "        \"\"\"\n",
        "        Initialize the Speech-to-Text MedGemma system.\n",
        "\n",
        "        Args:\n",
        "            model_variant (str): \"4b-it\" or \"27b-text-it\"\n",
        "            use_quantization (bool): Whether to use 4-bit quantization\n",
        "            is_thinking (bool): Enable thinking mode (27B variant only)\n",
        "        \"\"\"\n",
        "        self.model_variant = model_variant\n",
        "        self.model_id = f\"google/medgemma-{model_variant}\"\n",
        "        self.use_quantization = use_quantization\n",
        "        self.is_thinking = is_thinking\n",
        "        self.google_colab = \"google.colab\" in sys.modules and not os.environ.get(\"VERTEX_PRODUCT\")\n",
        "\n",
        "        # Initialize speech recognition\n",
        "        self.recognizer = sr.Recognizer()\n",
        "        self.microphone = sr.Microphone()\n",
        "\n",
        "        # Setup authentication and model\n",
        "        self._setup_authentication()\n",
        "        self._install_dependencies()\n",
        "        self._setup_model()\n",
        "\n",
        "    def _setup_authentication(self):\n",
        "        \"\"\"Setup Hugging Face authentication following the official pattern\"\"\"\n",
        "        if self.google_colab:\n",
        "            # Use secret if running in Google Colab\n",
        "            from google.colab import userdata\n",
        "            os.environ[\"HF_TOKEN\"] = userdata.get(\"HF_TOKEN\")\n",
        "        else:\n",
        "            # Store Hugging Face data under `/content` if running in Colab Enterprise\n",
        "            if os.environ.get(\"VERTEX_PRODUCT\") == \"COLAB_ENTERPRISE\":\n",
        "                os.environ[\"HF_HOME\"] = \"/content/hf\"\n",
        "            # Authenticate with Hugging Face\n",
        "            from huggingface_hub import get_token\n",
        "            if get_token() is None:\n",
        "                from huggingface_hub import notebook_login\n",
        "                notebook_login()\n",
        "\n",
        "    def _install_dependencies(self):\n",
        "        \"\"\"Install required dependencies\"\"\"\n",
        "        dependencies = [\n",
        "            \"speechrecognition\",\n",
        "            \"pyaudio\",\n",
        "            \"accelerate\",\n",
        "            \"bitsandbytes\",\n",
        "            \"transformers\"\n",
        "        ]\n",
        "\n",
        "        for dep in dependencies:\n",
        "            os.system(f\"pip install --upgrade --quiet {dep}\")\n",
        "\n",
        "    def _setup_model(self):\n",
        "        \"\"\"Setup the MedGemma model following the official configuration\"\"\"\n",
        "        print(\"Setting up MedGemma model...\")\n",
        "\n",
        "        # Check memory requirements for 27B model\n",
        "        if \"27b\" in self.model_variant and self.google_colab:\n",
        "            if not (\"A100\" in torch.cuda.get_device_name(0) and self.use_quantization):\n",
        "                raise ValueError(\n",
        "                    \"Runtime has insufficient memory to run the 27B variant. \"\n",
        "                    \"Please select an A100 GPU and use 4-bit quantization.\"\n",
        "                )\n",
        "\n",
        "        # Model configuration following official pattern\n",
        "        self.model_kwargs = dict(\n",
        "            torch_dtype=torch.bfloat16,\n",
        "            device_map=\"auto\",\n",
        "        )\n",
        "\n",
        "        if self.use_quantization:\n",
        "            self.model_kwargs[\"quantization_config\"] = BitsAndBytesConfig(load_in_4bit=True)\n",
        "\n",
        "        # Check if this is a text-only variant\n",
        "        self.is_text_only = \"text\" in self.model_variant\n",
        "\n",
        "        # Setup pipeline for text generation\n",
        "        self.text_pipe = pipeline(\n",
        "            \"text-generation\",\n",
        "            model=self.model_id,\n",
        "            model_kwargs=self.model_kwargs,\n",
        "        )\n",
        "        self.text_pipe.model.generation_config.do_sample = False\n",
        "\n",
        "        # Setup multimodal pipeline if not text-only\n",
        "        if not self.is_text_only:\n",
        "            try:\n",
        "                self.image_text_pipe = pipeline(\n",
        "                    \"image-text-to-text\",\n",
        "                    model=self.model_id,\n",
        "                    model_kwargs=self.model_kwargs,\n",
        "                )\n",
        "                self.image_text_pipe.model.generation_config.do_sample = False\n",
        "            except Exception as e:\n",
        "                print(f\"Warning: Could not setup multimodal pipeline: {e}\")\n",
        "                self.image_text_pipe = None\n",
        "\n",
        "        print(\"Model setup complete!\")\n",
        "\n",
        "    def calibrate_microphone(self):\n",
        "        \"\"\"Calibrate microphone for ambient noise\"\"\"\n",
        "        print(\"Calibrating microphone for ambient noise...\")\n",
        "        try:\n",
        "            with self.microphone as source:\n",
        "                self.recognizer.adjust_for_ambient_noise(source, duration=1)\n",
        "            print(\"Microphone calibrated!\")\n",
        "        except Exception as e:\n",
        "            print(f\"Warning: Could not calibrate microphone: {e}\")\n",
        "\n",
        "    def listen_for_speech(self, timeout=10, phrase_time_limit=None):\n",
        "        \"\"\"\n",
        "        Listen for speech input from microphone\n",
        "\n",
        "        Args:\n",
        "            timeout (int): Maximum seconds to wait for speech\n",
        "            phrase_time_limit (int): Maximum seconds for a phrase\n",
        "\n",
        "        Returns:\n",
        "            str: Transcribed text or None if failed\n",
        "        \"\"\"\n",
        "        try:\n",
        "            print(\"üé§ Listening for speech...\")\n",
        "            with self.microphone as source:\n",
        "                # Listen for audio with timeout\n",
        "                audio = self.recognizer.listen(\n",
        "                    source,\n",
        "                    timeout=timeout,\n",
        "                    phrase_time_limit=phrase_time_limit\n",
        "                )\n",
        "\n",
        "            print(\"üîÑ Processing speech...\")\n",
        "            # Convert speech to text using Google's speech recognition\n",
        "            text = self.recognizer.recognize_google(audio)\n",
        "            print(f\"üìù Transcribed: '{text}'\")\n",
        "            return text\n",
        "\n",
        "        except sr.WaitTimeoutError:\n",
        "            print(\"‚è∞ No speech detected within timeout period\")\n",
        "            return None\n",
        "        except sr.UnknownValueError:\n",
        "            print(\"‚ùå Could not understand the speech\")\n",
        "            return None\n",
        "        except sr.RequestError as e:\n",
        "            print(f\"üö´ Error with speech recognition service: {e}\")\n",
        "            return None\n",
        "\n",
        "    def generate_text_response(self, user_input, system_instruction=\"You are a helpful medical assistant.\"):\n",
        "        \"\"\"\n",
        "        Generate response using MedGemma for text-only input\n",
        "\n",
        "        Args:\n",
        "            user_input (str): User's input text\n",
        "            system_instruction (str): System instruction for the model\n",
        "\n",
        "        Returns:\n",
        "            str: Generated response\n",
        "        \"\"\"\n",
        "        # Prepare system instruction for thinking mode (following official pattern)\n",
        "        role_instruction = system_instruction\n",
        "        if \"27b\" in self.model_variant and self.is_thinking:\n",
        "            system_instruction = f\"SYSTEM INSTRUCTION: think silently if needed. {role_instruction}\"\n",
        "            max_new_tokens = 1500\n",
        "        else:\n",
        "            system_instruction = role_instruction\n",
        "            max_new_tokens = 500\n",
        "\n",
        "        # Prepare messages following official format\n",
        "        messages = [\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": system_instruction\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": user_input\n",
        "            }\n",
        "        ]\n",
        "\n",
        "        print(\"üß† Generating response...\")\n",
        "\n",
        "        # Generate response using pipeline (following official pattern)\n",
        "        output = self.text_pipe(messages, max_new_tokens=max_new_tokens)\n",
        "        response = output[0][\"generated_text\"][-1][\"content\"]\n",
        "\n",
        "        # Handle thinking mode output (following official pattern)\n",
        "        thought = None\n",
        "        if \"27b\" in self.model_variant and self.is_thinking and \"<unused95>\" in response:\n",
        "            thought, response = response.split(\"<unused95>\")\n",
        "            thought = thought.replace(\"<unused94>thought\\n\", \"\")\n",
        "\n",
        "        return response, thought\n",
        "\n",
        "    def generate_multimodal_response(self, user_input, image_path, system_instruction=\"You are an expert radiologist.\"):\n",
        "        \"\"\"\n",
        "        Generate response using MedGemma for image + text input\n",
        "\n",
        "        Args:\n",
        "            user_input (str): User's text input\n",
        "            image_path (str): Path to the image file\n",
        "            system_instruction (str): System instruction for the model\n",
        "\n",
        "        Returns:\n",
        "            str: Generated response\n",
        "        \"\"\"\n",
        "        if self.is_text_only or self.image_text_pipe is None:\n",
        "            return \"This model variant does not support image inputs.\", None\n",
        "\n",
        "        try:\n",
        "            # Load image\n",
        "            image = Image.open(image_path)\n",
        "\n",
        "            # Format conversation following official pattern\n",
        "            messages = [\n",
        "                {\n",
        "                    \"role\": \"system\",\n",
        "                    \"content\": [{\"type\": \"text\", \"text\": system_instruction}]\n",
        "                },\n",
        "                {\n",
        "                    \"role\": \"user\",\n",
        "                    \"content\": [\n",
        "                        {\"type\": \"text\", \"text\": user_input},\n",
        "                        {\"type\": \"image\", \"image\": image}\n",
        "                    ]\n",
        "                }\n",
        "            ]\n",
        "\n",
        "            print(\"üß† Generating multimodal response...\")\n",
        "\n",
        "            # Generate response using pipeline\n",
        "            output = self.image_text_pipe(text=messages, max_new_tokens=300)\n",
        "            response = output[0][\"generated_text\"][-1][\"content\"]\n",
        "\n",
        "            return response, None\n",
        "\n",
        "        except Exception as e:\n",
        "            return f\"Error processing image: {e}\", None\n",
        "\n",
        "    def run_interactive_session(self, enable_multimodal=False):\n",
        "        \"\"\"\n",
        "        Run an interactive speech-to-text session\n",
        "\n",
        "        Args:\n",
        "            enable_multimodal (bool): Whether to enable image input support\n",
        "        \"\"\"\n",
        "        print(\"üè• Starting MedGemma Speech-to-Text Medical Assistant\")\n",
        "        print(\"=\" * 60)\n",
        "        print(\"Commands:\")\n",
        "        print(\"- Say 'quit' or 'exit' to end the session\")\n",
        "        if enable_multimodal and not self.is_text_only:\n",
        "            print(\"- Type 'image' to upload an image for analysis\")\n",
        "        print(\"- Press Enter and start speaking for medical questions\")\n",
        "        print(\"=\" * 60)\n",
        "\n",
        "        # Calibrate microphone\n",
        "        self.calibrate_microphone()\n",
        "\n",
        "        while True:\n",
        "            print(f\"\\n{'='*20} New Interaction {'='*20}\")\n",
        "\n",
        "            # Check for special commands\n",
        "            user_command = input(\"üîπ Press Enter to speak, or type a command: \").strip().lower()\n",
        "\n",
        "            if user_command in ['quit', 'exit']:\n",
        "                print(\"üëã Goodbye! Stay healthy!\")\n",
        "                break\n",
        "\n",
        "            if user_command == 'image' and enable_multimodal and not self.is_text_only:\n",
        "                # Handle image input\n",
        "                image_path = input(\"üìÅ Enter image path: \").strip()\n",
        "                if not os.path.exists(image_path):\n",
        "                    print(\"‚ùå Image file not found!\")\n",
        "                    continue\n",
        "\n",
        "                # Get speech input for image description\n",
        "                print(\"üé§ Now speak your question about the image...\")\n",
        "                transcribed_text = self.listen_for_speech(timeout=15, phrase_time_limit=15)\n",
        "\n",
        "                if transcribed_text is None:\n",
        "                    print(\"‚ùå No valid speech input received.\")\n",
        "                    continue\n",
        "\n",
        "                if transcribed_text.lower() in ['quit', 'exit', 'stop']:\n",
        "                    break\n",
        "\n",
        "                # Generate multimodal response\n",
        "                try:\n",
        "                    response, thought = self.generate_multimodal_response(\n",
        "                        transcribed_text,\n",
        "                        image_path,\n",
        "                        \"You are an expert radiologist.\"\n",
        "                    )\n",
        "\n",
        "                    # Display results\n",
        "                    self._display_results(transcribed_text, response, thought, image_path=image_path)\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"‚ùå Error generating response: {e}\")\n",
        "\n",
        "                continue\n",
        "\n",
        "            # Regular speech input\n",
        "            transcribed_text = self.listen_for_speech(timeout=15, phrase_time_limit=15)\n",
        "\n",
        "            if transcribed_text is None:\n",
        "                print(\"‚ùå No valid speech input received. Try again.\")\n",
        "                continue\n",
        "\n",
        "            # Check if user wants to quit\n",
        "            if transcribed_text.lower() in ['quit', 'exit', 'stop']:\n",
        "                print(\"üëã Goodbye! Stay healthy!\")\n",
        "                break\n",
        "\n",
        "            # Generate text response\n",
        "            try:\n",
        "                response, thought = self.generate_text_response(\n",
        "                    transcribed_text,\n",
        "                    \"You are a helpful medical assistant.\"\n",
        "                )\n",
        "\n",
        "                # Display results\n",
        "                self._display_results(transcribed_text, response, thought)\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"‚ùå Error generating response: {e}\")\n",
        "\n",
        "    def _display_results(self, user_input, response, thought=None, image_path=None):\n",
        "        \"\"\"Display the conversation results in a formatted way\"\"\"\n",
        "        print(f\"\\nüó£Ô∏è  **User Speech Input:**\")\n",
        "        print(f\"   '{user_input}'\")\n",
        "\n",
        "        if image_path:\n",
        "            print(f\"üì∑ **Image:** {image_path}\")\n",
        "\n",
        "        if thought:\n",
        "            print(f\"\\nü§î **MedGemma Thinking:**\")\n",
        "            print(f\"   {thought}\")\n",
        "\n",
        "        print(f\"\\nüè• **MedGemma Response:**\")\n",
        "        print(\"-\" * 60)\n",
        "        print(response)\n",
        "        print(\"-\" * 60)\n",
        "\n",
        "    def process_single_speech_input(self, system_instruction=\"You are a helpful medical assistant.\"):\n",
        "        \"\"\"\n",
        "        Process a single speech input and return response\n",
        "\n",
        "        Args:\n",
        "            system_instruction (str): System instruction for the model\n",
        "\n",
        "        Returns:\n",
        "            tuple: (transcribed_text, response, thought)\n",
        "        \"\"\"\n",
        "        print(\"üé§ Speak now...\")\n",
        "\n",
        "        # Calibrate microphone if not done\n",
        "        self.calibrate_microphone()\n",
        "\n",
        "        # Listen for speech\n",
        "        transcribed_text = self.listen_for_speech(timeout=15, phrase_time_limit=15)\n",
        "\n",
        "        if transcribed_text is None:\n",
        "            return None, None, None\n",
        "\n",
        "        # Generate response\n",
        "        response, thought = self.generate_text_response(transcribed_text, system_instruction)\n",
        "\n",
        "        return transcribed_text, response, thought\n",
        "\n",
        "def main():\n",
        "    \"\"\"Main execution function\"\"\"\n",
        "    print(\"üöÄ Initializing MedGemma Speech-to-Text Medical Assistant...\")\n",
        "    print(\"Copyright 2025 Google LLC - Licensed under Apache License 2.0\")\n",
        "    print(\"-\" * 60)\n",
        "\n",
        "    try:\n",
        "        # Initialize the system with configuration\n",
        "        stt_medgemma = SpeechToTextMedGemma(\n",
        "            model_variant=\"4b-it\",  # Change to \"27b-text-it\" for text-only 27B model\n",
        "            use_quantization=True,\n",
        "            is_thinking=False  # Set to True for 27B variant with thinking mode\n",
        "        )\n",
        "\n",
        "        # Display model information\n",
        "        print(f\"‚úÖ Model loaded: {stt_medgemma.model_id}\")\n",
        "        print(f\"‚úÖ Text-only variant: {stt_medgemma.is_text_only}\")\n",
        "        print(f\"‚úÖ Quantization enabled: {stt_medgemma.use_quantization}\")\n",
        "        print(f\"‚úÖ Thinking mode: {stt_medgemma.is_thinking}\")\n",
        "\n",
        "        # Choose execution mode\n",
        "        print(\"\\nSelect mode:\")\n",
        "        print(\"1. Interactive session (recommended)\")\n",
        "        print(\"2. Single question mode\")\n",
        "\n",
        "        choice = input(\"Enter choice (1 or 2): \").strip()\n",
        "\n",
        "        if choice == \"1\":\n",
        "            # Interactive session with multimodal support\n",
        "            enable_multimodal = not stt_medgemma.is_text_only\n",
        "            stt_medgemma.run_interactive_session(enable_multimodal=enable_multimodal)\n",
        "\n",
        "        elif choice == \"2\":\n",
        "            # Single input mode\n",
        "            transcribed_text, response, thought = stt_medgemma.process_single_speech_input()\n",
        "            if transcribed_text:\n",
        "                stt_medgemma._display_results(transcribed_text, response, thought)\n",
        "            else:\n",
        "                print(\"‚ùå No speech input received.\")\n",
        "\n",
        "        else:\n",
        "            print(\"‚ùå Invalid choice. Please run again.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error initializing system: {e}\")\n",
        "        print(\"Please check your setup and try again.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ]
}