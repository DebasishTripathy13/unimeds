{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DebasishTripathy13/unimeds/blob/main/Whispermedium.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6MWGKax9VQVQ",
        "outputId": "7b2c49cf-6ec3-44f3-ef66-bcfd1db66617"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using CPU with int8 precision.\n",
            "Loading Faster-Whisper model: medium...\n",
            "Successfully loaded medium model on cpu!\n",
            "\n",
            "======================================================================\n",
            "üöÄ Hindi to English Speech Translator Ready for Direct Use!\n",
            "======================================================================\n",
            "Model: medium, Device: cpu, Compute Type: int8\n",
            "\n",
            "üí° To run your downloaded audio file, execute `test_audio_file_directly('your_file_name.mp3')` in a new cell.\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "# Hindi to English Speech-to-Text using Faster-Whisper on Google Colab\n",
        "# This notebook transcribes Hindi audio and translates it to English with improved accuracy and large file handling.\n",
        "\n",
        "# Install required packages (all in one go)\n",
        "!pip install --quiet faster-whisper\n",
        "!pip install --quiet gradio # Keep gradio installed as its part of the previous script, though not used in this direct execution\n",
        "!pip install --quiet soundfile\n",
        "!pip install --quiet gtts\n",
        "!pip install --quiet pydub # For audio manipulation (optional, but good for large files)\n",
        "\n",
        "import faster_whisper\n",
        "import gradio as gr # Still imported, but not used for direct execution\n",
        "import torch\n",
        "import librosa\n",
        "import numpy as np\n",
        "import os\n",
        "from IPython.display import Audio, display # For playing audio directly in Colab\n",
        "from google.colab import files # IMPORTANT for uploading!\n",
        "import io\n",
        "from gtts import gTTS\n",
        "import soundfile as sf # Explicitly import soundfile for sf.write\n",
        "\n",
        "# --- Configuration ---\n",
        "MODEL_SIZE = \"medium\" # Recommended for best accuracy\n",
        "if torch.cuda.is_available():\n",
        "    COMPUTE_TYPE = \"float16\"\n",
        "    DEVICE = \"cuda\"\n",
        "    print(f\"Using GPU ({torch.cuda.get_device_name(0)}) with {COMPUTE_TYPE} precision.\")\n",
        "else:\n",
        "    COMPUTE_TYPE = \"int8\"\n",
        "    DEVICE = \"cpu\"\n",
        "    print(f\"Using CPU with {COMPUTE_TYPE} precision.\")\n",
        "\n",
        "# Load Faster-Whisper model (this will download if not cached)\n",
        "print(f\"Loading Faster-Whisper model: {MODEL_SIZE}...\")\n",
        "try:\n",
        "    model = faster_whisper.WhisperModel(MODEL_SIZE, device=DEVICE, compute_type=COMPUTE_TYPE)\n",
        "    print(f\"Successfully loaded {MODEL_SIZE} model on {DEVICE}!\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading model: {e}\")\n",
        "    print(\"Attempting to load on CPU as a fallback...\")\n",
        "    model = faster_whisper.WhisperModel(MODEL_SIZE, device=\"cpu\", compute_type=\"int8\")\n",
        "    DEVICE = \"cpu\"\n",
        "    print(f\"Successfully loaded {MODEL_SIZE} model on CPU!\")\n",
        "\n",
        "# --- Transcription Function ---\n",
        "def transcribe_hindi_to_english(audio_path_or_array, language=\"hi\"):\n",
        "    \"\"\"\n",
        "    Transcribe Hindi audio and translate it to English using Faster-Whisper.\n",
        "    Handles both file paths and numpy arrays. Automatically chunks large audio files for processing.\n",
        "\n",
        "    Args:\n",
        "        audio_path_or_array: Path to audio file (string) or audio array (tuple from Gradio).\n",
        "        language (str): Source language (default: \"hi\" for Hindi).\n",
        "\n",
        "    Returns:\n",
        "        dict: Contains transcribed and translated text, detected language, and confidence.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # If it's a Gradio numpy input, convert to a temporary file\n",
        "        if isinstance(audio_path_or_array, tuple):\n",
        "            sample_rate, audio_data = audio_path_or_array\n",
        "            temp_audio_file = \"temp_gradio_audio.wav\"\n",
        "\n",
        "            # Ensure audio data is float32 for soundfile.write\n",
        "            if audio_data.dtype in [np.int16, np.int32]:\n",
        "                audio_data = audio_data.astype(np.float32) / np.iinfo(audio_data.dtype).max\n",
        "            elif audio_data.dtype == np.uint8:\n",
        "                 audio_data = (audio_data.astype(np.float32) - 128) / 128.0\n",
        "\n",
        "\n",
        "            if sample_rate != 16000:\n",
        "                audio_data = librosa.resample(audio_data, orig_sr=sample_rate, target_sr=16000)\n",
        "                sample_rate = 16000\n",
        "            if len(audio_data.shape) > 1: # Convert stereo to mono\n",
        "                audio_data = np.mean(audio_data, axis=1)\n",
        "\n",
        "            sf.write(temp_audio_file, audio_data, sample_rate)\n",
        "            audio_source = temp_audio_file\n",
        "        else:\n",
        "            audio_source = audio_path_or_array # It's already a file path\n",
        "\n",
        "        print(f\"Starting transcription for: {audio_source}\")\n",
        "\n",
        "        segments, info = model.transcribe(\n",
        "            audio=audio_source,\n",
        "            language=language,\n",
        "            task=\"translate\",\n",
        "            beam_size=5,\n",
        "            vad_filter=True,\n",
        "            vad_parameters={\"min_silence_duration_ms\": 500},\n",
        "            without_timestamps=False\n",
        "        )\n",
        "\n",
        "        full_translation = \"\"\n",
        "        # You can also get word-level timestamps if needed, for \"word to word conversion\" insight\n",
        "        word_level_transcription = []\n",
        "\n",
        "        print(f\"Detected language: {info.language} with probability {info.language_probability:.4f}\")\n",
        "\n",
        "        for segment in segments:\n",
        "            full_translation += segment.text.strip() + \" \"\n",
        "            # Uncomment below to collect word-level details for \"word to word\" inspection\n",
        "            # for word in segment.words:\n",
        "            #    word_level_transcription.append(f\"'{word.word}' ({word.start:.2f}s-{word.end:.2f}s)\")\n",
        "\n",
        "        # Clean up temporary audio file if created\n",
        "        if 'temp_audio_file' in locals() and os.path.exists(temp_audio_file):\n",
        "            os.remove(temp_audio_file)\n",
        "\n",
        "        return {\n",
        "            \"detected_language\": info.language,\n",
        "            \"confidence\": f\"{info.language_probability:.2%}\",\n",
        "            \"english_translation\": full_translation.strip(),\n",
        "            # \"word_level_transcription\": \"\\n\".join(word_level_transcription)\n",
        "        }\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error during transcription: {e}\")\n",
        "        if 'temp_audio_file' in locals() and os.path.exists(temp_audio_file):\n",
        "            os.remove(temp_audio_file)\n",
        "        return {\n",
        "            \"error\": f\"Transcription failed: {str(e)}\",\n",
        "            \"detected_language\": \"Unknown\",\n",
        "            \"confidence\": \"0%\",\n",
        "            \"english_translation\": \"\"\n",
        "        }\n",
        "\n",
        "# --- Helper Functions for Direct Testing in Colab (These are included in your main script) ---\n",
        "def create_sample_hindi_audio(filename=\"sample_hindi.mp3\", text=\"‡§®‡§Æ‡§∏‡•ç‡§§‡•á, ‡§Æ‡•à‡§Ç ‡§è‡§ï ‡§™‡§∞‡•Ä‡§ï‡•ç‡§∑‡§£ ‡§∏‡§Ç‡§¶‡•á‡§∂ ‡§π‡•Ç‡§Ç‡•§ ‡§Ø‡§π ‡§≤‡§Ç‡§¨‡•Ä ‡§ë‡§°‡§ø‡§Ø‡•ã ‡§´‡§æ‡§á‡§≤ ‡§ï‡•á ‡§≤‡§ø‡§è ‡§π‡•à‡•§\"):\n",
        "    try:\n",
        "        tts = gTTS(text=text, lang='hi')\n",
        "        tts.save(filename)\n",
        "        print(f\"‚úÖ Sample Hindi audio created: '{filename}'\")\n",
        "        display(Audio(filename, autoplay=False))\n",
        "        return filename\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error creating sample audio: {e}\")\n",
        "        return None\n",
        "\n",
        "def upload_and_test_audio():\n",
        "    print(\"\\nüìÅ Please select your Hindi audio MP3 file...\")\n",
        "    uploaded = files.upload()\n",
        "    if not uploaded:\n",
        "        print(\"‚ùå No file uploaded.\")\n",
        "        return\n",
        "    filename = list(uploaded.keys())[0]\n",
        "    print(f\"\\nüéØ Processing uploaded file: '{filename}'\")\n",
        "    result = transcribe_hindi_to_english(filename)\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"üéØ TRANSCRIPTION RESULTS\")\n",
        "    print(\"=\"*60)\n",
        "    if 'error' in result:\n",
        "        print(f\"Error: {result['error']}\")\n",
        "    else:\n",
        "        print(f\"üìÅ File: {filename}\")\n",
        "        print(f\"üó£Ô∏è Detected Language: {result.get('detected_language', 'N/A')}\")\n",
        "        print(f\"üìä Confidence: {result.get('confidence', 'N/A')}\")\n",
        "        print(f\"\\nüåê ENGLISH TRANSLATION:\")\n",
        "        print(\"-\" * 40)\n",
        "        print(f\"'{result.get('english_translation', 'No translation available')}'\")\n",
        "    print(\"=\"*60)\n",
        "    return result\n",
        "\n",
        "def test_audio_file_directly(file_path):\n",
        "    if not os.path.exists(file_path):\n",
        "        print(f\"‚ùå Error: File '{file_path}' not found!\")\n",
        "        print(\"Make sure the file is uploaded to Colab or check the path.\")\n",
        "        return\n",
        "\n",
        "    print(f\"\\nüéØ Processing file: '{file_path}'\")\n",
        "    result = transcribe_hindi_to_english(file_path)\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"üéØ TRANSCRIPTION RESULTS\")\n",
        "    print(\"=\"*60)\n",
        "    if 'error' in result:\n",
        "        print(f\"Error: {result['error']}\")\n",
        "    else:\n",
        "        print(f\"üìÅ File: {file_path}\")\n",
        "        print(f\"üó£Ô∏è Detected Language: {result.get('detected_language', 'N/A')}\")\n",
        "        print(f\"üìä Confidence: {result.get('confidence', 'N/A')}\")\n",
        "        print(f\"\\nüåê ENGLISH TRANSLATION:\")\n",
        "        print(\"-\" * 40)\n",
        "        print(f\"'{result.get('english_translation', 'No translation available')}'\")\n",
        "    print(\"=\"*60)\n",
        "    return result\n",
        "\n",
        "# --- Main Execution Block (for direct use without Gradio interface launch) ---\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"üöÄ Hindi to English Speech Translator Ready for Direct Use!\")\n",
        "    print(\"=\"*70)\n",
        "    print(f\"Model: {MODEL_SIZE}, Device: {DEVICE}, Compute Type: {COMPUTE_TYPE}\")\n",
        "    print(\"\\nüí° To run your downloaded audio file, execute `test_audio_file_directly('your_file_name.mp3')` in a new cell.\")\n",
        "    print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "ExCZ0fhJzcTk",
        "outputId": "f2970e68-3a57-491e-a2bd-1adfffc98bb7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please select your Hindi audio MP3 file...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-7d902e5a-53a0-4f6a-9ae8-1ca0eea1ee60\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-7d902e5a-53a0-4f6a-9ae8-1ca0eea1ee60\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving my_hindi_audio.mp3 to my_hindi_audio.mp3\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "\n",
        "print(\"Please select your Hindi audio MP3 file...\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "# After running this, a \"Choose Files\" button will appear.\n",
        "# Click it, navigate to your MP3 file, and select it.\n",
        "# Once uploaded, it will show a message like:\n",
        "# 'your_audio.mp3' (audio/mpeg) - 123456 bytes uploaded."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UUK6AMCf1n_P",
        "outputId": "4e8b9da1-fc15-4691-8a1a-2e2b2c5aae29"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üéØ Processing file: 'my_hindi_audio.mp3'\n",
            "Starting transcription for: my_hindi_audio.mp3\n",
            "Detected language: hi with probability 1.0000\n",
            "\n",
            "============================================================\n",
            "üéØ TRANSCRIPTION RESULTS\n",
            "============================================================\n",
            "üìÅ File: my_hindi_audio.mp3\n",
            "üó£Ô∏è Detected Language: hi\n",
            "üìä Confidence: 100.00%\n",
            "\n",
            "üåê ENGLISH TRANSLATION:\n",
            "----------------------------------------\n",
            "'Once upon a time, there was a farmer living in a village. He was very fond of raising animals. He already had a lot of buffaloes. He used to sell their milk and run his own house. One day, the farmer raised a rabbit and a monkey in his house. After a long time, the farmer decided to play with the rabbit and the monkey. The farmer made a lot of small pits in his field. He put soil on the pits and closed them. The farmer hid a carrot in one of the pits. The farmer asked the rabbit and the monkey to find the carrot. The rabbit was very confident and had a lot of confidence in himself. He started digging one pit and started finding the carrot. But the monkey was very negative and lazy. He thought that there are so many pits in the field. Who will find the carrot in one of the pits? The monkey went to sleep on one of the pits. The rabbit was trying his best to find the carrot. One by one, the rabbit saw all the pits. But he didn't find the carrot in any of the pits. Only one pit was left and the monkey was sleeping on it. The rabbit went to the monkey and asked him to get up from the pit. As soon as the monkey got up from the pit, the rabbit dug the pit and took out the carrot. And gave it to its owner. The monkey was surprised to see that the carrot was inside the pit he was sleeping on. If he had dug the pit only once, he would have found the carrot. And he would have become a big man in the eyes of the owner. He regretted what he had done. Friends, from this story, we get three big lessons. The first one is that we should never think negatively about our work. Like the monkey thought that there are so many pits and the carrot is in one of the pits. Thinking this, he made that work big for himself. And the second lesson we get from this story is that we should at least try. Because until we try, fate will not support us. If the monkey had started digging the pit from where he was sleeping, he would have found the carrot. But he never tried. And the third lesson we get from this story is that we should not give up early. Now we don't know when we will be successful in our work. It can be 2025, 2030 or even 2032. But we will be successful only when we keep trying with positive thinking. And we will not give up. So if you want to make this story reach more people, then like this video. So that YouTube can make this video reach more people. And if you liked the story, then do subscribe to our channel. I will see you next time with a similar story. So be patient, be grateful and move forward in life.'\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'detected_language': 'hi',\n",
              " 'confidence': '100.00%',\n",
              " 'english_translation': \"Once upon a time, there was a farmer living in a village. He was very fond of raising animals. He already had a lot of buffaloes. He used to sell their milk and run his own house. One day, the farmer raised a rabbit and a monkey in his house. After a long time, the farmer decided to play with the rabbit and the monkey. The farmer made a lot of small pits in his field. He put soil on the pits and closed them. The farmer hid a carrot in one of the pits. The farmer asked the rabbit and the monkey to find the carrot. The rabbit was very confident and had a lot of confidence in himself. He started digging one pit and started finding the carrot. But the monkey was very negative and lazy. He thought that there are so many pits in the field. Who will find the carrot in one of the pits? The monkey went to sleep on one of the pits. The rabbit was trying his best to find the carrot. One by one, the rabbit saw all the pits. But he didn't find the carrot in any of the pits. Only one pit was left and the monkey was sleeping on it. The rabbit went to the monkey and asked him to get up from the pit. As soon as the monkey got up from the pit, the rabbit dug the pit and took out the carrot. And gave it to its owner. The monkey was surprised to see that the carrot was inside the pit he was sleeping on. If he had dug the pit only once, he would have found the carrot. And he would have become a big man in the eyes of the owner. He regretted what he had done. Friends, from this story, we get three big lessons. The first one is that we should never think negatively about our work. Like the monkey thought that there are so many pits and the carrot is in one of the pits. Thinking this, he made that work big for himself. And the second lesson we get from this story is that we should at least try. Because until we try, fate will not support us. If the monkey had started digging the pit from where he was sleeping, he would have found the carrot. But he never tried. And the third lesson we get from this story is that we should not give up early. Now we don't know when we will be successful in our work. It can be 2025, 2030 or even 2032. But we will be successful only when we keep trying with positive thinking. And we will not give up. So if you want to make this story reach more people, then like this video. So that YouTube can make this video reach more people. And if you liked the story, then do subscribe to our channel. I will see you next time with a similar story. So be patient, be grateful and move forward in life.\"}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# Assuming your file is named 'my_hindi_speech.mp3'\n",
        "test_audio_file_directly('my_hindi_audio.mp3')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2O0yu5I0Qtr"
      },
      "source": [
        "# New Section"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "toc_visible": true,
      "provenance": [],
      "authorship_tag": "ABX9TyN7mSUcJZy9Il4shmOnVHBM",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}